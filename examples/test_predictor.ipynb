{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d9bb4f",
   "metadata": {},
   "source": [
    "## MENGUJI MANUAL PREDICTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.datasets import make_regression\n",
    "from noventis.predictor import ManualPredictor\n",
    "\n",
    "def test_manual_regression():\n",
    "    \"\"\"\n",
    "    Fungsi untuk menguji ManualPredictor pada tugas regresi.\n",
    "    Menggunakan data sintetis.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ MEMULAI PENGUJIAN: MANUAL PREDICTOR UNTUK REGRESI\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # --- 1. Persiapan Data dan Direktori ---\n",
    "    output_dir = \"noventis_output/regression_manual\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Direktori output disiapkan di: {output_dir}\")\n",
    "\n",
    "    # Membuat data regresi sintetis\n",
    "    X, y = make_regression(n_samples=200, n_features=10, noise=25, random_state=42)\n",
    "    df_regr = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\n",
    "    df_regr['target'] = y\n",
    "    print(\"‚úÖ Dataset regresi sintetis berhasil dibuat.\")\n",
    "    print(\"Data head:\")\n",
    "    print(df_regr.head())\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # --- 2. Menjalankan Pipeline dengan Satu Model ---\n",
    "    print(\"\\n--- Menjalankan ManualPredictor (Single Model: XGBoost) ---\")\n",
    "    manual_predictor_single = ManualPredictor(model_name='xgboost', task='regression')\n",
    "\n",
    "    # Jalankan pipeline\n",
    "    result_single = manual_predictor_single.run_pipeline(df=df_regr, target_column='target')\n",
    "    print(f\"Model: {result_single['model_name']}, R2-Score: {result_single['metrics']['r2_score']:.4f}\")\n",
    "\n",
    "    # Simpan model\n",
    "    model_path = os.path.join(output_dir, \"best_xgboost_model.pkl\")\n",
    "    manual_predictor_single.save_model(model_path)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # --- 3. Menjalankan Pipeline dengan Perbandingan Beberapa Model ---\n",
    "    print(\"\\n--- Menjalankan ManualPredictor (Multiple Models Comparison) ---\")\n",
    "    manual_predictor_multi = ManualPredictor(\n",
    "        model_name=['linear_regression', 'random_forest', 'lightgbm'],\n",
    "        task='regression'\n",
    "    )\n",
    "    result_multi = manual_predictor_multi.run_pipeline(df=df_regr, target_column='target')\n",
    "\n",
    "    print(\"\\n--- Hasil Perbandingan Manual ---\")\n",
    "    best_model_details = result_multi['best_model_details']\n",
    "    print(f\"Model terbaik: {best_model_details['model_name']}, R2-Score: {best_model_details['metrics']['r2_score']:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    print(\"\\nüéâ Pengujian Regresi Selesai.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_manual_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfdffb",
   "metadata": {},
   "source": [
    "## MENGUJI AUTO PREDICTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600aeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\env3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data berhasil dimuat dari DataFrame\n",
      "üìä Shape data: (53940, 11)\n",
      "üìã Kolom: ['Unnamed_0', 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
      "‚úÖ Tipe tugas terdeteksi: classification\n",
      "‚úÖ Data berhasil dibagi: Train=43152, Test=10788\n",
      "üìà Target distribution: {2.0: 21551, 3.0: 13791, 4.0: 12082, 1.0: 4906, 0.0: 1610}\n",
      "üöÄ Memulai proses AutoML dengan FLAML...\n",
      "‚è≥ Melatih model (Metrik: macro_f1, Waktu: 300s)...\n",
      "üíæ Model berhasil disimpan di: Noventis_Results\\best_automl_model.pkl\n",
      "üìä Membuat visualisasi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Menjalankan pipeline untuk model tunggal: logistic_regression\n",
      "INFO:root:--- Memproses model: LOGISTIC_REGRESSION ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Summary report disimpan di: Noventis_Results\\model_summary.txt\n",
      "üìä Visualisasi berhasil dibuat dan disimpan di direktori 'Noventis_Results'!\n",
      "\n",
      "üîç Memulai perbandingan dengan model lain...\n",
      "\n",
      "==================== Melatih Logistic Regression ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training selesai dalam 12.98 detik.\n",
      "INFO:root:Menjalankan pipeline untuk model tunggal: random_forest\n",
      "INFO:root:--- Memproses model: RANDOM_FOREST ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ logistic_regression berhasil dilatih\n",
      "\n",
      "==================== Melatih Random Forest ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training selesai dalam 19.68 detik.\n",
      "INFO:root:Menjalankan pipeline untuk model tunggal: xgboost\n",
      "INFO:root:--- Memproses model: XGBOOST ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ random_forest berhasil dilatih\n",
      "\n",
      "==================== Melatih Xgboost ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training selesai dalam 1.39 detik.\n",
      "INFO:root:Menjalankan pipeline untuk model tunggal: svm\n",
      "INFO:root:--- Memproses model: SVM ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ xgboost berhasil dilatih\n",
      "\n",
      "==================== Melatih Svm ====================\n",
      "‚ùå Error saat melatih svm: Model 'svm' tidak dikenal untuk tugas classification.\n",
      "üìÑ Comparison report disimpan di: Noventis_Results\\model_comparison_report.txt\n",
      "üìä Hasil perbandingan model disimpan di direktori 'Noventis_Results'.\n",
      "\n",
      "üéâ Proses AutoML Selesai!\n",
      "üèÜ Estimator terbaik: xgboost\n",
      "üìä Metrics: {'accuracy': 0.7808676307007787, 'f1_score_macro': 0.774426829700831, 'f1_score_micro': 0.7808676307007787, 'f1_score_weighted': 0.770420028157452, 'precision_macro': 0.805649567868751, 'recall_macro': 0.7616720795068627}\n",
      "\n",
      "üìä Advanced Results:\n",
      "Best Model: xgboost\n",
      "Model Comparison: {'rankings': [{'model': 'Automl Flaml', 'score': -1, 'metrics': {'accuracy': 0.7808676307007787, 'f1_score_macro': 0.774426829700831, 'f1_score_micro': 0.7808676307007787, 'f1_score_weighted': 0.770420028157452, 'precision_macro': 0.805649567868751, 'recall_macro': 0.7616720795068627}}, {'model': 'Logistic Regression', 'score': -1, 'metrics': {'f1_score': 0.31666940898946494}}, {'model': 'Random Forest', 'score': -1, 'metrics': {'f1_score': 0.774963398000972}}, {'model': 'Xgboost', 'score': -1, 'metrics': {'f1_score': 0.800907818218218}}], 'best_model': 'Automl Flaml', 'primary_metric': 'macro_f1'}\n"
     ]
    }
   ],
   "source": [
    "# examples/test_automl.py\n",
    "\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import dataset_for_examples\n",
    "\n",
    "from noventis.predictor import NoventisAutoML\n",
    "from noventis import data_cleaner\n",
    "\n",
    "def test_automl_classification():\n",
    "    \"\"\"\n",
    "    Fungsi untuk menguji NoventisAutoML pada tugas klasifikasi.\n",
    "    Menggunakan dataset Iris.\n",
    "    \"\"\"\n",
    "\n",
    "    # ===================================================================\n",
    "    # CONTOH PENGGUNAAN NoventisAutoML\n",
    "    # ===================================================================\n",
    "    # Load data\n",
    "    df_raw = pd.read_csv('../dataset_for_examples/diamonds.csv') # Atau gunakan DataFrame langsung\n",
    "    df_raw.columns = df_raw.columns.str.replace(r'[^A-Za-z0-9_]+', '_', regex=True)\n",
    "\n",
    "    # df = data_cleaner(\n",
    "    #     data=df_raw,\n",
    "    #     target_column='cut',\n",
    "    #     outlier_handling=False,\n",
    "    # )\n",
    "    # Automatically select columns of type 'object'\n",
    "    categorical_cols = df_raw.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Create a copy\n",
    "    df_ordinal = df_raw.copy()\n",
    "\n",
    "    # Create and apply the encoder\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    df_ordinal[categorical_cols] = ordinal_encoder.fit_transform(df_ordinal[categorical_cols])\n",
    "\n",
    "    # ===================================================================\n",
    "    # 1. BASIC USAGE - AutoML Sederhana\n",
    "    # ===================================================================\n",
    "    # Initialize NoventisAutoML\n",
    "    \n",
    "    # automl = NoventisAutoML(\n",
    "    #     data=df_ordinal,                    # Dataset (CSV path atau DataFrame)\n",
    "    #     target='cut',     # Nama kolom target\n",
    "    #     task='classification',      # 'classification' atau 'regression' (optional, auto-detect)\n",
    "    #     test_size=0.2,             # Proporsi data test\n",
    "    #     random_state=42            # Random seed untuk reproducibility\n",
    "    # )\n",
    "\n",
    "    # # Train model dengan visualisasi\n",
    "    # results = automl.fit(\n",
    "    #     time_budget=120,           # Waktu training dalam detik\n",
    "    #     metric='macro_f1',         # Metrik evaluasi (optional)\n",
    "    #     explain=True,              # Generate visualisasi dan penjelasan\n",
    "    #     compare=False,             # Bandingkan dengan model lain\n",
    "    #     output_dir='results',       # Direktori output\n",
    "    # )\n",
    "\n",
    "    # print(\"üéâ Training selesai!\")\n",
    "    # print(f\"Best Model: {results['best_estimator']}\")\n",
    "    # print(f\"Metrics: {results['metrics']}\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 2. ADVANCED USAGE - Dengan Perbandingan Model\n",
    "    # ===================================================================\n",
    "    \n",
    "    # Initialize dengan auto-detection task type\n",
    "    automl_advanced = NoventisAutoML(\n",
    "        data=df_ordinal,\n",
    "        target='cut',            # Untuk regression example\n",
    "    )\n",
    "\n",
    "    # Training dengan perbandingan model\n",
    "    advanced_results = automl_advanced.fit(\n",
    "        time_budget=300,           # 5 menit training\n",
    "        explain=True,              # Generate semua visualisasi\n",
    "        compare=True,              # Bandingkan dengan model manual\n",
    "        output_dir='advanced_results',\n",
    "        \n",
    "        # FLAML specific parameters\n",
    "        estimator_list=['xgboost', 'lightgbm', 'decision_tree'],  # Model yang dicoba\n",
    "        # eval_method='cv',          # Cross-validation\n",
    "        # split_ratio=0.8,          # Train/validation split\n",
    "        # n_splits=5,               # CV folds\n",
    "        # ensemble=True             # Enable ensemble\n",
    "    )\n",
    "\n",
    "    print(\"\\nüìä Advanced Results:\")\n",
    "    print(f\"Best Model: {advanced_results['best_estimator']}\")\n",
    "    print(f\"Model Comparison: {advanced_results.get('model_comparison', 'Not available')}\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 3. MANUAL MODEL COMPARISON\n",
    "    # ===================================================================\n",
    "    '''\n",
    "    # Jika ingin compare model secara terpisah\n",
    "    comparison_results = automl.compare_models(\n",
    "        models_to_compare=['logistic_regression', 'random_forest', 'xgboost', 'svm'],\n",
    "        output_dir='comparison_results'\n",
    "    )\n",
    "\n",
    "    print(\"\\nüèÜ Model Rankings:\")\n",
    "    for i, model_info in enumerate(comparison_results['rankings'], 1):\n",
    "        print(f\"{i}. {model_info['model']}: {model_info['score']:.4f}\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 4. PREDIKSI DENGAN MODEL YANG SUDAH DILATIH\n",
    "    # ===================================================================\n",
    "\n",
    "    # Data baru untuk prediksi\n",
    "    new_data = df.drop('cut', axis=1)  # Tanpa kolom target\n",
    "\n",
    "    # Prediksi menggunakan model yang sudah dilatih\n",
    "    predictions = automl.predict(new_data)\n",
    "    print(\"\\nüîÆ Prediksi baru:\")\n",
    "    print(predictions['predictions'][:10])  # Show first 10 predictions\n",
    "\n",
    "    # Jika classification, akan ada probabilitas\n",
    "    if 'probabilities' in predictions:\n",
    "        print(\"Probabilitas:\")\n",
    "        print(predictions['probabilities'][:5])\n",
    "\n",
    "    # ===================================================================\n",
    "    # 5. LOAD MODEL DARI FILE\n",
    "    # ===================================================================\n",
    "\n",
    "    # Load saved model\n",
    "    saved_model = automl.load_model('results/best_automl_model.pkl')\n",
    "\n",
    "    # Prediksi dengan loaded model\n",
    "    predictions_from_saved = automl.predict(new_data, model_path='results/best_automl_model.pkl')\n",
    "\n",
    "    # ===================================================================\n",
    "    # 6. EXPORT HASIL KE CSV\n",
    "    # ===================================================================\n",
    "\n",
    "    # Export semua hasil ke CSV\n",
    "    automl.export_results_to_csv(output_dir='exported_results')\n",
    "\n",
    "    # ===================================================================\n",
    "    # 7. GET MODEL INFORMATION\n",
    "    # ===================================================================\n",
    "\n",
    "    # Dapatkan info detail model\n",
    "    model_info = automl.get_model_info()\n",
    "    print(\"\\nüìã Model Information:\")\n",
    "    for key, value in model_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 8. HYPERPARAMETER SUGGESTIONS\n",
    "    # ===================================================================\n",
    "\n",
    "    # Dapatkan saran hyperparameter untuk model terbaik\n",
    "    hp_suggestions = automl.get_hyperparameter_suggestions()\n",
    "    print(\"\\n‚öôÔ∏è Hyperparameter Suggestions:\")\n",
    "    print(hp_suggestions)\n",
    "\n",
    "    # ===================================================================\n",
    "    # 9. CUSTOM CONFIGURATION EXAMPLES\n",
    "    # ===================================================================\n",
    "\n",
    "    # Classification dengan konfigurasi khusus\n",
    "    classification_automl = NoventisAutoML(\n",
    "        data=df,\n",
    "        target='category',\n",
    "        task='classification'\n",
    "    )\n",
    "\n",
    "    classification_results = classification_automl.fit(\n",
    "        time_budget=180,\n",
    "        metric='roc_auc',\n",
    "        explain=True,\n",
    "        compare=True,\n",
    "        \n",
    "        # FLAML Advanced Settings\n",
    "        estimator_list=['lgbm', 'xgboost', 'catboost'],\n",
    "        log_training_metric=True,\n",
    "        verbose=1,\n",
    "        retrain_full=True,\n",
    "        split_type='stratified',\n",
    "        hpo_method='cfo',          # Hyperparameter optimization method\n",
    "        starting_points='data'      # Starting points for HPO\n",
    "    )\n",
    "\n",
    "    # Regression dengan konfigurasi khusus\n",
    "    regression_automl = NoventisAutoML(\n",
    "        data='house_prices.csv',\n",
    "        target='price',\n",
    "        task='regression'\n",
    "    )\n",
    "\n",
    "    regression_results = regression_automl.fit(\n",
    "        time_budget=240,\n",
    "        metric='rmse',\n",
    "        explain=True,\n",
    "        compare=True,\n",
    "        \n",
    "        # Custom settings\n",
    "        estimator_list=['lgbm', 'xgboost', 'rf', 'extra_tree'],\n",
    "        ensemble=True,\n",
    "        max_iter=100,\n",
    "        early_stop=True,\n",
    "        split_ratio=0.75\n",
    "    )\n",
    "\n",
    "    # ===================================================================\n",
    "    # 10. ERROR HANDLING EXAMPLE\n",
    "    # ===================================================================\n",
    "\n",
    "    try:\n",
    "        # Initialize dengan data yang mungkin bermasalah\n",
    "        problematic_automl = NoventisAutoML(\n",
    "            data='might_not_exist.csv',\n",
    "            target='target'\n",
    "        )\n",
    "        \n",
    "        results = problematic_automl.fit(\n",
    "            time_budget=60,\n",
    "            explain=True,\n",
    "            compare=True\n",
    "        )\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå File dataset tidak ditemukan!\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"‚ùå Error dalam konfigurasi: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 11. BATCH PROCESSING EXAMPLE\n",
    "    # ===================================================================\n",
    "\n",
    "    # Process multiple datasets\n",
    "    datasets = ['dataset1.csv', 'dataset2.csv', 'dataset3.csv']\n",
    "    targets = ['target1', 'target2', 'target3']\n",
    "\n",
    "    batch_results = {}\n",
    "\n",
    "    for dataset, target in zip(datasets, targets):\n",
    "        try:\n",
    "            print(f\"\\nüîÑ Processing {dataset}...\")\n",
    "            \n",
    "            automl_batch = NoventisAutoML(\n",
    "                data=dataset,\n",
    "                target=target\n",
    "            )\n",
    "            \n",
    "            result = automl_batch.fit(\n",
    "                time_budget=120,\n",
    "                explain=True,\n",
    "                compare=False,\n",
    "                output_dir=f'batch_results/{dataset.split(\".\")[0]}'\n",
    "            )\n",
    "            \n",
    "            batch_results[dataset] = {\n",
    "                'best_model': result['best_estimator'],\n",
    "                'performance': result['metrics'],\n",
    "                'success': True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {dataset}: {e}\")\n",
    "            batch_results[dataset] = {'success': False, 'error': str(e)}\n",
    "\n",
    "    # Print batch results summary\n",
    "    print(\"\\nüìä Batch Processing Summary:\")\n",
    "    for dataset, result in batch_results.items():\n",
    "        if result['success']:\n",
    "            print(f\"‚úÖ {dataset}: {result['best_model']} - {result['performance']}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {dataset}: Failed - {result['error']}\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 12. REAL-TIME MONITORING EXAMPLE\n",
    "    # ===================================================================\n",
    "\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "\n",
    "    class AutoMLMonitor:\n",
    "        def __init__(self):\n",
    "            self.start_time = None\n",
    "            self.results = []\n",
    "        \n",
    "        def run_automl_with_monitoring(self, data, target, time_budget=300):\n",
    "            self.start_time = datetime.now()\n",
    "            print(f\"üöÄ Starting AutoML at {self.start_time}\")\n",
    "            \n",
    "            automl = NoventisAutoML(data=data, target=target)\n",
    "            \n",
    "            # Custom callback untuk monitoring (jika FLAML support)\n",
    "            results = automl.fit(\n",
    "                time_budget=time_budget,\n",
    "                explain=True,\n",
    "                compare=True,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            duration = (end_time - self.start_time).total_seconds()\n",
    "            \n",
    "            self.results.append({\n",
    "                'start_time': self.start_time,\n",
    "                'end_time': end_time,\n",
    "                'duration': duration,\n",
    "                'best_model': results['best_estimator'],\n",
    "                'performance': results['metrics']\n",
    "            })\n",
    "            \n",
    "            print(f\"‚úÖ AutoML completed in {duration:.2f} seconds\")\n",
    "            return results\n",
    "\n",
    "    # Usage\n",
    "    monitor = AutoMLMonitor()\n",
    "    monitored_results = monitor.run_automl_with_monitoring(\n",
    "        data='large_dataset.csv',\n",
    "        target='target_column',\n",
    "        time_budget=600  # 10 minutes\n",
    "    )\n",
    "\n",
    "    print(\"\\nüìà Monitoring Results:\")\n",
    "    print(f\"Total Duration: {monitor.results[-1]['duration']:.2f} seconds\")\n",
    "    print(f\"Best Model: {monitor.results[-1]['best_model']}\")\n",
    "    '''\n",
    "    # ===================================================================\n",
    "    # OUTPUT FILES YANG DIHASILKAN:\n",
    "    # ===================================================================\n",
    "    \"\"\"\n",
    "    Setelah menjalankan NoventisAutoML dengan explain=True, \n",
    "    file-file berikut akan dibuat di output directory:\n",
    "\n",
    "    üìÅ output_directory/\n",
    "    ‚îú‚îÄ‚îÄ üìä feature_importance.png          # Feature importance plot\n",
    "    ‚îú‚îÄ‚îÄ üìà training_history.png           # Training progress curve\n",
    "    ‚îú‚îÄ‚îÄ üîç confusion_matrix.png           # Confusion matrix (classification)\n",
    "    ‚îú‚îÄ‚îÄ üìä classification_metrics.png     # Classification metrics bar plot\n",
    "    ‚îú‚îÄ‚îÄ üìà predictions_vs_actual.png      # Pred vs actual (regression)\n",
    "    ‚îú‚îÄ‚îÄ üìä residuals_plot.png            # Residuals plot (regression)\n",
    "    ‚îú‚îÄ‚îÄ üìä regression_metrics.png        # Regression metrics bar plot\n",
    "    ‚îú‚îÄ‚îÄ üìä model_comparison.png          # Model comparison (jika compare=True)\n",
    "    ‚îú‚îÄ‚îÄ üå°Ô∏è metrics_heatmap.png           # Metrics heatmap across models\n",
    "    ‚îú‚îÄ‚îÄ üíæ best_automl_model.pkl         # Saved best model\n",
    "    ‚îú‚îÄ‚îÄ üìÑ model_summary.txt             # Model summary report\n",
    "    ‚îú‚îÄ‚îÄ üìÑ model_comparison_report.txt   # Comparison report (jika compare=True)\n",
    "    ‚îú‚îÄ‚îÄ üìÑ flaml.log                     # FLAML training log\n",
    "    ‚îú‚îÄ‚îÄ üìä predictions.csv               # Predictions hasil\n",
    "    ‚îú‚îÄ‚îÄ üìä metrics.csv                   # Metrics hasil\n",
    "    ‚îî‚îÄ‚îÄ üìä feature_importance.csv        # Feature importance data\n",
    "    \"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_automl_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345c883c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Unnamed_0  53940 non-null  int64  \n",
      " 1   carat      53940 non-null  float64\n",
      " 2   cut        53940 non-null  object \n",
      " 3   color      53940 non-null  object \n",
      " 4   clarity    53940 non-null  object \n",
      " 5   depth      53940 non-null  float64\n",
      " 6   table      53940 non-null  float64\n",
      " 7   price      53940 non-null  int64  \n",
      " 8   x          53940 non-null  float64\n",
      " 9   y          53940 non-null  float64\n",
      " 10  z          53940 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('../dataset_for_examples/diamonds.csv') # Atau gunakan DataFrame langsung\n",
    "df_raw.columns = df_raw.columns.str.replace(r'[^A-Za-z0-9_]+', '_', regex=True)\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587e7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "       Unnamed_0  carat        cut color clarity  depth  table  price     x  \\\n",
      "0              1   0.23      Ideal     E     SI2   61.5   55.0    326  3.95   \n",
      "1              2   0.21    Premium     E     SI1   59.8   61.0    326  3.89   \n",
      "2              3   0.23       Good     E     VS1   56.9   65.0    327  4.05   \n",
      "3              4   0.29    Premium     I     VS2   62.4   58.0    334  4.20   \n",
      "4              5   0.31       Good     J     SI2   63.3   58.0    335  4.34   \n",
      "...          ...    ...        ...   ...     ...    ...    ...    ...   ...   \n",
      "53935      53936   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75   \n",
      "53936      53937   0.72       Good     D     SI1   63.1   55.0   2757  5.69   \n",
      "53937      53938   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66   \n",
      "53938      53939   0.86    Premium     H     SI2   61.0   58.0   2757  6.15   \n",
      "53939      53940   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83   \n",
      "\n",
      "          y     z  \n",
      "0      3.98  2.43  \n",
      "1      3.84  2.31  \n",
      "2      4.07  2.31  \n",
      "3      4.23  2.63  \n",
      "4      4.35  2.75  \n",
      "...     ...   ...  \n",
      "53935  5.76  3.50  \n",
      "53936  5.75  3.61  \n",
      "53937  5.68  3.56  \n",
      "53938  6.12  3.74  \n",
      "53939  5.87  3.64  \n",
      "\n",
      "[53940 rows x 11 columns]\n",
      "\n",
      "Categorical columns to encode:\n",
      "['cut', 'color', 'clarity']\n",
      "DataFrame after Ordinal Encoding 'Size':\n",
      "       Unnamed_0  carat  cut  color  clarity  depth  table  price     x     y  \\\n",
      "0              1   0.23  2.0    1.0      3.0   61.5   55.0    326  3.95  3.98   \n",
      "1              2   0.21  3.0    1.0      2.0   59.8   61.0    326  3.89  3.84   \n",
      "2              3   0.23  1.0    1.0      4.0   56.9   65.0    327  4.05  4.07   \n",
      "3              4   0.29  3.0    5.0      5.0   62.4   58.0    334  4.20  4.23   \n",
      "4              5   0.31  1.0    6.0      3.0   63.3   58.0    335  4.34  4.35   \n",
      "...          ...    ...  ...    ...      ...    ...    ...    ...   ...   ...   \n",
      "53935      53936   0.72  2.0    0.0      2.0   60.8   57.0   2757  5.75  5.76   \n",
      "53936      53937   0.72  1.0    0.0      2.0   63.1   55.0   2757  5.69  5.75   \n",
      "53937      53938   0.70  4.0    0.0      2.0   62.8   60.0   2757  5.66  5.68   \n",
      "53938      53939   0.86  3.0    4.0      3.0   61.0   58.0   2757  6.15  6.12   \n",
      "53939      53940   0.75  2.0    0.0      3.0   62.2   55.0   2757  5.83  5.87   \n",
      "\n",
      "          z  \n",
      "0      2.43  \n",
      "1      2.31  \n",
      "2      2.31  \n",
      "3      2.63  \n",
      "4      2.75  \n",
      "...     ...  \n",
      "53935  3.50  \n",
      "53936  3.61  \n",
      "53937  3.56  \n",
      "53938  3.74  \n",
      "53939  3.64  \n",
      "\n",
      "[53940 rows x 11 columns]\n",
      "‚úÖ Data berhasil dimuat dari DataFrame\n",
      "üìä Shape data: (53940, 11)\n",
      "üìã Kolom: ['Unnamed_0', 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
      "‚úÖ Tipe tugas terdeteksi: classification\n",
      "‚úÖ Data berhasil dibagi: Train=40455, Test=13485\n",
      "üìà Target distribution: {2.0: 21551, 3.0: 13791, 4.0: 12082, 1.0: 4906, 0.0: 1610}\n",
      "\n",
      "üìä Advanced Results:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     53\u001b[39m advanced_results = flaml_model.fit(\n\u001b[32m     54\u001b[39m     X, y\n\u001b[32m     55\u001b[39m )\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Advanced Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43madvanced_results\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest_estimator\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel Comparison: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madvanced_results.get(\u001b[33m'\u001b[39m\u001b[33mmodel_comparison\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNot available\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from flaml import AutoML as FLAMLAutoML\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_raw = pd.read_csv('../dataset_for_examples/diamonds.csv') # Atau gunakan DataFrame langsung\n",
    "df_raw.columns = df_raw.columns.str.replace(r'[^A-Za-z0-9_]+', '_', regex=True)\n",
    "\n",
    "categorical_cols = df_raw.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_raw)\n",
    "print(\"\\nCategorical columns to encode:\")\n",
    "print(list(categorical_cols))\n",
    "\n",
    "# Create a copy\n",
    "df_ordinal = df_raw.copy()\n",
    "\n",
    "# Create and apply the encoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "df_ordinal[categorical_cols] = ordinal_encoder.fit_transform(df_ordinal[categorical_cols])\n",
    "X, y = df_ordinal.drop(columns=['cut']), df_ordinal['cut']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=random_state, stratify=stratify\n",
    "# )\n",
    "\n",
    "print(\"DataFrame after Ordinal Encoding 'Size':\")\n",
    "print(df_ordinal)\n",
    "\n",
    "automl_advanced = NoventisAutoML(\n",
    "    data=df_ordinal,\n",
    "    target='cut',            # Untuk regression example\n",
    "    test_size=0.25,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "flaml_model = FLAMLAutoML(\n",
    "    task='classification', \n",
    "    metric = 'macro_f1', \n",
    "    time_budget=300,\n",
    "    seed=123, \n",
    "    # log_file_name=f'{output_dir}/flaml.log', \n",
    "    output_dir = 'advanced_results',\n",
    "    verbose=2,\n",
    "    estimator_list=['lgbm', 'xgboost', 'rf'],  # Model yang dicoba\n",
    "    eval_method='cv',          # Cross-validation\n",
    "    split_ratio=0.8,          # Train/validation split\n",
    "    n_splits=5,               # CV folds\n",
    "    ensemble=True,             # Enable ensemble\n",
    ")\n",
    "        \n",
    "# Training dengan perbandingan model\n",
    "advanced_results = flaml_model.fit(\n",
    "    X, y\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Advanced Results:\")\n",
    "print(f\"\")\n",
    "print(f\"Model Comparison: {advanced_results.get('model_comparison', 'Not available')}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
